{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e6da9f-9cda-406a-97da-6340e78b7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.config import INDICATORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c964532-d8c1-49f6-a552-370c1db10fe1",
   "metadata": {},
   "source": [
    "# 1. Data Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ab98ef-a806-4476-ad06-b3bc39cacfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2020-01-01'\n",
    "TRAIN_END_DATE = '2020-10-01'\n",
    "TRADE_START_DATE = '2021-10-01'\n",
    "TRADE_END_DATE = '2021-12-31'\n",
    "\n",
    "symbols = [\n",
    "    'BTC-USD',\n",
    "    'ETH-USD',\n",
    "    'USDT-USD',\n",
    "    'BNB-USD',\n",
    "    'XRP-USD',\n",
    "    'SOL-USD',\n",
    "    'DOGE-USD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9717af2a-8e07-4104-b9f4-b6658284311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (5010, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: use Binance for higher resolution data\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "\n",
    "df_raw = YahooDownloader(\n",
    "    start_date = TRAIN_START_DATE,\n",
    "    end_date = TRADE_END_DATE,\n",
    "    ticker_list = symbols).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777c8e60-fe26-4307-9bd6-b24064e9ccf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>13.730962</td>\n",
       "      <td>13.873946</td>\n",
       "      <td>13.654942</td>\n",
       "      <td>13.689083</td>\n",
       "      <td>172980718</td>\n",
       "      <td>BNB-USD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7194.892090</td>\n",
       "      <td>7254.330566</td>\n",
       "      <td>7174.944336</td>\n",
       "      <td>7200.174316</td>\n",
       "      <td>18565664997</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>51180941</td>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>129.630661</td>\n",
       "      <td>132.835358</td>\n",
       "      <td>129.198288</td>\n",
       "      <td>130.802002</td>\n",
       "      <td>7935230330</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.999571</td>\n",
       "      <td>1.006873</td>\n",
       "      <td>0.994924</td>\n",
       "      <td>0.999836</td>\n",
       "      <td>21503143454</td>\n",
       "      <td>USDT-USD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         open         high          low        close  \\\n",
       "0  2020-01-01    13.730962    13.873946    13.654942    13.689083   \n",
       "1  2020-01-01  7194.892090  7254.330566  7174.944336  7200.174316   \n",
       "2  2020-01-01     0.002028     0.002052     0.002021     0.002033   \n",
       "3  2020-01-01   129.630661   132.835358   129.198288   130.802002   \n",
       "4  2020-01-01     0.999571     1.006873     0.994924     0.999836   \n",
       "\n",
       "        volume       tic  day  \n",
       "0    172980718   BNB-USD    2  \n",
       "1  18565664997   BTC-USD    2  \n",
       "2     51180941  DOGE-USD    2  \n",
       "3   7935230330   ETH-USD    2  \n",
       "4  21503143454  USDT-USD    2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da341d3d-bf15-4557-a449-094ea184b460",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4c90f9-14f5-41dc-95f2-302a591d130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Shape of DataFrame:  (503, 8)\n",
      "Successfully added vix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,\n",
    "    tech_indicator_list = INDICATORS,\n",
    "    use_vix=True,\n",
    "    use_turbulence=True,\n",
    "    user_defined_feature=False)\n",
    "processed = fe.preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f68db3a-efe5-4d1e-b4fa-3619ad834b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>1.000461</td>\n",
       "      <td>1.000839</td>\n",
       "      <td>1.000089</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>66373042997</td>\n",
       "      <td>USDT-USD</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1.001149</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>49.648675</td>\n",
       "      <td>8.288201</td>\n",
       "      <td>8.505671</td>\n",
       "      <td>1.000311</td>\n",
       "      <td>1.000370</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>0.857945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0.204427</td>\n",
       "      <td>0.224607</td>\n",
       "      <td>0.201994</td>\n",
       "      <td>0.223010</td>\n",
       "      <td>1435469263</td>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.015081</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.184723</td>\n",
       "      <td>46.407834</td>\n",
       "      <td>-61.404033</td>\n",
       "      <td>19.639277</td>\n",
       "      <td>0.239858</td>\n",
       "      <td>0.258971</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>3.639011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>7116.552734</td>\n",
       "      <td>7167.183105</td>\n",
       "      <td>7050.332031</td>\n",
       "      <td>7096.184570</td>\n",
       "      <td>32513423567</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>4</td>\n",
       "      <td>33.379509</td>\n",
       "      <td>7525.739363</td>\n",
       "      <td>6164.819622</td>\n",
       "      <td>48.861196</td>\n",
       "      <td>91.553264</td>\n",
       "      <td>0.672650</td>\n",
       "      <td>6685.716553</td>\n",
       "      <td>7394.056958</td>\n",
       "      <td>38.150002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>362.360870</td>\n",
       "      <td>418.665131</td>\n",
       "      <td>350.956787</td>\n",
       "      <td>401.262329</td>\n",
       "      <td>4486850584</td>\n",
       "      <td>BNB-USD</td>\n",
       "      <td>2</td>\n",
       "      <td>-47.368550</td>\n",
       "      <td>592.453219</td>\n",
       "      <td>196.187480</td>\n",
       "      <td>48.217678</td>\n",
       "      <td>-41.784957</td>\n",
       "      <td>19.091366</td>\n",
       "      <td>472.624957</td>\n",
       "      <td>496.276307</td>\n",
       "      <td>17.480000</td>\n",
       "      <td>1.522098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>442.406250</td>\n",
       "      <td>442.479309</td>\n",
       "      <td>415.667725</td>\n",
       "      <td>435.401367</td>\n",
       "      <td>2006344571</td>\n",
       "      <td>BNB-USD</td>\n",
       "      <td>2</td>\n",
       "      <td>4.524209</td>\n",
       "      <td>461.230330</td>\n",
       "      <td>314.112736</td>\n",
       "      <td>53.963482</td>\n",
       "      <td>84.819060</td>\n",
       "      <td>2.003693</td>\n",
       "      <td>396.684233</td>\n",
       "      <td>421.376298</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.640698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date         open         high          low        close  \\\n",
       "2632  2021-09-28     1.000461     1.000839     1.000089     1.000298   \n",
       "2648  2021-10-01     0.204427     0.224607     0.201994     0.223010   \n",
       "439   2020-04-17  7116.552734  7167.183105  7050.332031  7096.184570   \n",
       "2136  2021-06-02   362.360870   418.665131   350.956787   401.262329   \n",
       "2664  2021-10-06   442.406250   442.479309   415.667725   435.401367   \n",
       "\n",
       "           volume       tic  day       macd      boll_ub      boll_lb  \\\n",
       "2632  66373042997  USDT-USD    1   0.000058     1.001149     0.999474   \n",
       "2648   1435469263  DOGE-USD    4  -0.015081     0.258875     0.184723   \n",
       "439   32513423567   BTC-USD    4  33.379509  7525.739363  6164.819622   \n",
       "2136   4486850584   BNB-USD    2 -47.368550   592.453219   196.187480   \n",
       "2664   2006344571   BNB-USD    2   4.524209   461.230330   314.112736   \n",
       "\n",
       "         rsi_30     cci_30      dx_30  close_30_sma  close_60_sma        vix  \\\n",
       "2632  49.648675   8.288201   8.505671      1.000311      1.000370  23.250000   \n",
       "2648  46.407834 -61.404033  19.639277      0.239858      0.258971  21.100000   \n",
       "439   48.861196  91.553264   0.672650   6685.716553   7394.056958  38.150002   \n",
       "2136  48.217678 -41.784957  19.091366    472.624957    496.276307  17.480000   \n",
       "2664  53.963482  84.819060   2.003693    396.684233    421.376298  21.000000   \n",
       "\n",
       "      turbulence  \n",
       "2632    0.857945  \n",
       "2648    3.639011  \n",
       "439     0.000000  \n",
       "2136    1.522098  \n",
       "2664    4.640698  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f503f2-0da5-4275-80b4-a86c055c5fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>BNB-USD</td>\n",
       "      <td>293.601318</td>\n",
       "      <td>300.993774</td>\n",
       "      <td>281.696106</td>\n",
       "      <td>299.282990</td>\n",
       "      <td>1849700307</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.343657</td>\n",
       "      <td>335.229220</td>\n",
       "      <td>275.736884</td>\n",
       "      <td>46.055664</td>\n",
       "      <td>-38.914501</td>\n",
       "      <td>21.081625</td>\n",
       "      <td>301.220141</td>\n",
       "      <td>326.472543</td>\n",
       "      <td>17.200001</td>\n",
       "      <td>0.737415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>62944678</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>56.800686</td>\n",
       "      <td>37.633930</td>\n",
       "      <td>45.041119</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>22.650000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>BNB-USD</td>\n",
       "      <td>24.074766</td>\n",
       "      <td>24.331917</td>\n",
       "      <td>22.215130</td>\n",
       "      <td>22.333511</td>\n",
       "      <td>298250332</td>\n",
       "      <td>2</td>\n",
       "      <td>1.475201</td>\n",
       "      <td>28.269995</td>\n",
       "      <td>16.339986</td>\n",
       "      <td>59.717923</td>\n",
       "      <td>52.048746</td>\n",
       "      <td>16.605669</td>\n",
       "      <td>20.760635</td>\n",
       "      <td>18.655989</td>\n",
       "      <td>14.380000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>1.354004</td>\n",
       "      <td>1.470145</td>\n",
       "      <td>1.324077</td>\n",
       "      <td>1.467735</td>\n",
       "      <td>13216559312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.215262</td>\n",
       "      <td>1.447483</td>\n",
       "      <td>0.155245</td>\n",
       "      <td>75.743241</td>\n",
       "      <td>214.862921</td>\n",
       "      <td>87.584176</td>\n",
       "      <td>0.697981</td>\n",
       "      <td>0.596036</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>34.179386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>9185.581055</td>\n",
       "      <td>9217.835938</td>\n",
       "      <td>9084.837891</td>\n",
       "      <td>9137.993164</td>\n",
       "      <td>15735797744</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.969738</td>\n",
       "      <td>9682.566656</td>\n",
       "      <td>9018.137348</td>\n",
       "      <td>50.007062</td>\n",
       "      <td>-116.012538</td>\n",
       "      <td>23.268076</td>\n",
       "      <td>9489.227214</td>\n",
       "      <td>9382.829232</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       tic         open         high          low  \\\n",
       "2352  2021-07-23   BNB-USD   293.601318   300.993774   281.696106   \n",
       "902   2020-08-06  DOGE-USD     0.003517     0.003636     0.003461   \n",
       "192   2020-02-19   BNB-USD    24.074766    24.331917    22.215130   \n",
       "1925  2021-04-12   XRP-USD     1.354004     1.470145     1.324077   \n",
       "745   2020-06-30   BTC-USD  9185.581055  9217.835938  9084.837891   \n",
       "\n",
       "            close       volume  day       macd      boll_ub      boll_lb  \\\n",
       "2352   299.282990   1849700307    4  -8.343657   335.229220   275.736884   \n",
       "902      0.003560     62944678    3   0.000115     0.003630     0.003039   \n",
       "192     22.333511    298250332    2   1.475201    28.269995    16.339986   \n",
       "1925     1.467735  13216559312    0   0.215262     1.447483     0.155245   \n",
       "745   9137.993164  15735797744    1 -72.969738  9682.566656  9018.137348   \n",
       "\n",
       "         rsi_30      cci_30      dx_30  close_30_sma  close_60_sma        vix  \\\n",
       "2352  46.055664  -38.914501  21.081625    301.220141    326.472543  17.200001   \n",
       "902   56.800686   37.633930  45.041119      0.003413      0.002937  22.650000   \n",
       "192   59.717923   52.048746  16.605669     20.760635     18.655989  14.380000   \n",
       "1925  75.743241  214.862921  87.584176      0.697981      0.596036  16.910000   \n",
       "745   50.007062 -116.012538  23.268076   9489.227214   9382.829232  30.430000   \n",
       "\n",
       "      turbulence  \n",
       "2352    0.737415  \n",
       "902     0.000000  \n",
       "192     0.000000  \n",
       "1925   34.179386  \n",
       "745     0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "list_ticker = processed['tic'].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).strftime('%Y-%m-%d'))\n",
    "#list_date\n",
    "combination = list(itertools.product(list_date, list_ticker))\n",
    "combination\n",
    "processed_full = pd.DataFrame(combination, columns=['date', 'tic']).merge(processed)\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.fillna(0)\n",
    "processed_full.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c441d-6e68-4036-b964-1c027133d6ea",
   "metadata": {},
   "source": [
    "# Data Split and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f29c94-aa54-46e4-b6ae-5f60ebb45c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE, TRADE_END_DATE)\n",
    "\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273acd40-6d5c-41e5-b5e2-fa0fac34a536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (1134, 18)\n"
     ]
    }
   ],
   "source": [
    "train.to_parquet(\"./train.parquet\")\n",
    "print(f\"train.shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3f9320-7e10-490f-98bc-8666fc4189e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade.shape: (372, 18)\n"
     ]
    }
   ],
   "source": [
    "trade.to_parquet(\"./trade.parquet\")\n",
    "print(f\"trade.shape: {trade.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7e8cc8-2c37-401a-a948-80050a6bdae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 6, State Space: 61\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1  + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb1d22-0c7a-448f-bacf-b488a90f800a",
   "metadata": {},
   "source": [
    "# Train, Test, and Make Env\n",
    "\n",
    "## Design Environment\n",
    "\n",
    "We'll be modeling our environment as a stock environment because the CryptoEnv built into FinRL Meta doesn't integrate well with other FinRL pipelines. Also, from the Agent's perspective the statespace, actions, and rewards are the same as a stock environment.\n",
    "\n",
    "TODO: try out the cryptoenv, by fixing ta-lib requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a5a3764-0940-43da-ab8f-4d9c4d043bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 6, State Space: 61\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed_full.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ccda05-bf26-4a07-9475-2d17f71e1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1_000_000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab14dd8-024d-4b2f-8ca5-e787137c9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19926f1-fca3-4f48-bf0e-ae40ed2e091a",
   "metadata": {},
   "source": [
    "# Initialize Agent & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7556a90e-46d6-4956-954c-7ae0b1b8801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c869a3b5-e8bf-4f57-8307-5a5d718f2e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.config import TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "    # set up logger\n",
    "    tmp_path = RESULTS_DIR + '/a2c'\n",
    "    new_logger_a2c = configure(tmp_path, ['stdout', 'csv', 'tensorboard'])\n",
    "    # set new logger\n",
    "    model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e252e9f-cd94-4309-954f-ad4bff0588c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 404        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.53      |\n",
      "|    explained_variance | -0.231     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -19.4      |\n",
      "|    reward             | -1.1550831 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 5.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 452      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.56    |\n",
      "|    explained_variance | 0.00759  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -49.1    |\n",
      "|    reward             | 4.002124 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 47.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 472        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.56      |\n",
      "|    explained_variance | -0.0329    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -118       |\n",
      "|    reward             | 0.72114456 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 285        |\n",
      "--------------------------------------\n",
      "day: 188, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1632796.04\n",
      "total_reward: 632796.04\n",
      "total_cost: 40144.75\n",
      "total_trades: 1059\n",
      "Sharpe: 1.328\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.57     |\n",
      "|    explained_variance | 0.00291   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 7.9       |\n",
      "|    reward             | 1.0515075 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 23        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 488      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.56    |\n",
      "|    explained_variance | -0.0525  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -66.4    |\n",
      "|    reward             | 4.113984 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 88.2     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 494        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.56      |\n",
      "|    explained_variance | -0.04      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -5.6       |\n",
      "|    reward             | -1.4738284 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 498       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.55     |\n",
      "|    explained_variance | -0.000496 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 11.4      |\n",
      "|    reward             | 1.6756428 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 44.1      |\n",
      "-------------------------------------\n",
      "day: 188, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1552649.32\n",
      "total_reward: 552649.32\n",
      "total_cost: 21777.86\n",
      "total_trades: 1013\n",
      "Sharpe: 1.212\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 501        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.55      |\n",
      "|    explained_variance | 0.00937    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 46         |\n",
      "|    reward             | -2.4631686 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 35.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 503       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.51     |\n",
      "|    explained_variance | -0.0584   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 22.6      |\n",
      "|    reward             | -6.300441 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 504      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.52    |\n",
      "|    explained_variance | 0.0412   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 141      |\n",
      "|    reward             | 3.53443  |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 323      |\n",
      "------------------------------------\n",
      "day: 188, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1188607.50\n",
      "total_reward: 188607.50\n",
      "total_cost: 39353.05\n",
      "total_trades: 958\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 506       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.5      |\n",
      "|    explained_variance | 0.0992    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -43.8     |\n",
      "|    reward             | 2.5416284 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 29.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 508         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.49       |\n",
      "|    explained_variance | 0.569       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -6.41       |\n",
      "|    reward             | -0.21043557 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 0.755       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.49      |\n",
      "|    explained_variance | -0.102     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -12.8      |\n",
      "|    reward             | -2.4530988 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 2.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.47      |\n",
      "|    explained_variance | 0.0434     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -13.1      |\n",
      "|    reward             | -0.3037034 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 77         |\n",
      "--------------------------------------\n",
      "day: 188, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1525310.14\n",
      "total_reward: 525310.14\n",
      "total_cost: 16422.35\n",
      "total_trades: 982\n",
      "Sharpe: 1.178\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 510       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.46     |\n",
      "|    explained_variance | 0.047     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -27.1     |\n",
      "|    reward             | 2.5456662 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 511      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.47    |\n",
      "|    explained_variance | 0.0152   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 52.9     |\n",
      "|    reward             | 2.368626 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 94.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 511       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.49     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 33        |\n",
      "|    reward             | 6.9513526 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 22        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 512        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.53      |\n",
      "|    explained_variance | 0.0269     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -28        |\n",
      "|    reward             | -1.7473418 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 17.3       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1524424.71\n",
      "total_reward: 524424.71\n",
      "total_cost: 1028.80\n",
      "total_trades: 962\n",
      "Sharpe: 1.170\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 512        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.55      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -115       |\n",
      "|    reward             | -7.6852565 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 206        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 513        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.57      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 17.2       |\n",
      "|    reward             | -5.2259464 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 10         |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 513      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.56    |\n",
      "|    explained_variance | 0.0163   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -13.5    |\n",
      "|    reward             | 1.790647 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 24.2     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 513         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.57       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -60.6       |\n",
      "|    reward             | -0.48954713 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 73          |\n",
      "---------------------------------------\n",
      "day: 188, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523098.69\n",
      "total_reward: 523098.69\n",
      "total_cost: 1000.78\n",
      "total_trades: 820\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | 1.7171787 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 7.83      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.6      |\n",
      "|    explained_variance | -0.00236  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 71.9      |\n",
      "|    reward             | -5.695812 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 97.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 514        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.6       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -4.32      |\n",
      "|    reward             | 0.98462516 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 7.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.6        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 130         |\n",
      "|    reward             | -0.55714744 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 289         |\n",
      "---------------------------------------\n",
      "day: 188, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523343.57\n",
      "total_reward: 523343.57\n",
      "total_cost: 999.39\n",
      "total_trades: 939\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 512       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.59     |\n",
      "|    explained_variance | 0.00552   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 18.4      |\n",
      "|    reward             | 13.926966 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 10.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 512        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.59      |\n",
      "|    explained_variance | 0.00206    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | 56.5       |\n",
      "|    reward             | -3.8773344 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 77.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 513        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.62      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -4.31      |\n",
      "|    reward             | 0.26561767 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.37       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523605.06\n",
      "total_reward: 523605.06\n",
      "total_cost: 1003.13\n",
      "total_trades: 846\n",
      "Sharpe: 1.169\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 513       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 17.4      |\n",
      "|    reward             | -6.400688 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.41      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 513      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    reward             | 5.937655 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.12     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 513         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.65       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 15.8        |\n",
      "|    reward             | -0.74446654 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 5.62        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 514        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.66      |\n",
      "|    explained_variance | 0.000727   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -57.2      |\n",
      "|    reward             | -0.7559286 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 307        |\n",
      "--------------------------------------\n",
      "day: 188, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523351.30\n",
      "total_reward: 523351.30\n",
      "total_cost: 999.42\n",
      "total_trades: 869\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 514        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.64      |\n",
      "|    explained_variance | 0.000908   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -34.5      |\n",
      "|    reward             | -0.4070063 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 52.7       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 514      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.64    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -9.96    |\n",
      "|    reward             | 2.209258 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 514        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.66      |\n",
      "|    explained_variance | 0.00137    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -31.2      |\n",
      "|    reward             | -16.853853 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 40.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -18.4     |\n",
      "|    reward             | 1.9398739 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 16.5      |\n",
      "-------------------------------------\n",
      "day: 188, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523236.33\n",
      "total_reward: 523236.33\n",
      "total_cost: 999.71\n",
      "total_trades: 927\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 514      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.7     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 41.5     |\n",
      "|    reward             | 4.857071 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 40.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 514      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 47.3     |\n",
      "|    reward             | -0.35401 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 46.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 44.3      |\n",
      "|    reward             | 2.8050795 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 40.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.72      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 77.7       |\n",
      "|    reward             | -1.5141164 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 140        |\n",
      "--------------------------------------\n",
      "day: 188, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523061.87\n",
      "total_reward: 523061.87\n",
      "total_cost: 1000.01\n",
      "total_trades: 938\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.71      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 31.9       |\n",
      "|    reward             | -0.7865392 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 18.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.71      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 20.6       |\n",
      "|    reward             | -1.0371288 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 5.09       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.69    |\n",
      "|    explained_variance | -0.00136 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -60.9    |\n",
      "|    reward             | 3.146054 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 52.7     |\n",
      "------------------------------------\n",
      "day: 188, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1454466.66\n",
      "total_reward: 454466.66\n",
      "total_cost: 1219.55\n",
      "total_trades: 925\n",
      "Sharpe: 1.086\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 43          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.69       |\n",
      "|    explained_variance | 8.33e-05    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -5.44       |\n",
      "|    reward             | -0.22086857 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 124         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.72       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -14         |\n",
      "|    reward             | 0.027775405 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 3.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.7        |\n",
      "|    explained_variance | -7.08e-05   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -9.92       |\n",
      "|    reward             | -0.82485914 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 10.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 516        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -57.5      |\n",
      "|    reward             | 0.96852297 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 59.8       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1585378.90\n",
      "total_reward: 585378.90\n",
      "total_cost: 13338.96\n",
      "total_trades: 938\n",
      "Sharpe: 1.245\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 516         |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.71       |\n",
      "|    explained_variance | -0.000328   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | -16.1       |\n",
      "|    reward             | -0.25339624 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 13.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 516        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.69      |\n",
      "|    explained_variance | 8.99e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | -97.5      |\n",
      "|    reward             | 0.18294781 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 163        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 516      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.68    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -17.7    |\n",
      "|    reward             | 1.461341 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 516        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.67      |\n",
      "|    explained_variance | 9.75e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | 23.4       |\n",
      "|    reward             | -1.8860468 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 18.8       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1519883.85\n",
      "total_reward: 519883.85\n",
      "total_cost: 5863.81\n",
      "total_trades: 938\n",
      "Sharpe: 1.166\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.68     |\n",
      "|    explained_variance | 0.000712  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -45.3     |\n",
      "|    reward             | 2.8019278 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 35        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.7      |\n",
      "|    explained_variance | 0.0603    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 68.3      |\n",
      "|    reward             | 2.5460117 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 58.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 516        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.71      |\n",
      "|    explained_variance | -0.00218   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -68.9      |\n",
      "|    reward             | 0.07144301 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 124        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 26.5      |\n",
      "|    reward             | 1.6871363 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 13.5      |\n",
      "-------------------------------------\n",
      "day: 188, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1496201.64\n",
      "total_reward: 496201.64\n",
      "total_cost: 6417.79\n",
      "total_trades: 940\n",
      "Sharpe: 1.137\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 516        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.71      |\n",
      "|    explained_variance | -0.00129   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | 48.5       |\n",
      "|    reward             | 0.30120742 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 52.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.73     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 46.4      |\n",
      "|    reward             | 2.9161928 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 39.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.75     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 45.4      |\n",
      "|    reward             | 6.5292115 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 40        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.75     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -9.11     |\n",
      "|    reward             | 2.8705032 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 2.49      |\n",
      "-------------------------------------\n",
      "day: 188, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523139.49\n",
      "total_reward: 523139.49\n",
      "total_cost: 3486.07\n",
      "total_trades: 938\n",
      "Sharpe: 1.170\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.76    |\n",
      "|    explained_variance | 0.00552  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 45.4     |\n",
      "|    reward             | -2.84495 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 37.2     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.76      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 14.2       |\n",
      "|    reward             | -1.1901413 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 11.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.77      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | -26.7      |\n",
      "|    reward             | -1.4815078 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 16.3       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1535493.58\n",
      "total_reward: 535493.58\n",
      "total_cost: 2012.29\n",
      "total_trades: 940\n",
      "Sharpe: 1.183\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.76     |\n",
      "|    explained_variance | 0.000695  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 89.1      |\n",
      "|    reward             | -3.482267 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 124       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.78      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 41.7       |\n",
      "|    reward             | -6.8979573 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 23.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.78     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 5.55      |\n",
      "|    reward             | 1.2238313 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.82      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 517         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.77       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -9.25       |\n",
      "|    reward             | 0.003491164 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "day: 188, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523225.08\n",
      "total_reward: 523225.08\n",
      "total_cost: 999.92\n",
      "total_trades: 934\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -29.5     |\n",
      "|    reward             | -7.799179 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 18.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.8       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -78.7      |\n",
      "|    reward             | -1.2137885 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 69.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.8       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 22.2       |\n",
      "|    reward             | -0.5143463 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 13.5       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.81    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | 32.2     |\n",
      "|    reward             | 6.818902 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 27.9     |\n",
      "------------------------------------\n",
      "day: 188, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1520253.51\n",
      "total_reward: 520253.51\n",
      "total_cost: 2802.35\n",
      "total_trades: 940\n",
      "Sharpe: 1.165\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 39.8      |\n",
      "|    reward             | 2.8785384 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 50.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 62.8     |\n",
      "|    reward             | 5.88022  |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 63       |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 36.1       |\n",
      "|    reward             | 0.18092422 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 19.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 8.62      |\n",
      "|    reward             | 1.6974399 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 13.3      |\n",
      "-------------------------------------\n",
      "day: 188, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1526085.29\n",
      "total_reward: 526085.29\n",
      "total_cost: 1621.94\n",
      "total_trades: 940\n",
      "Sharpe: 1.172\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.82     |\n",
      "|    explained_variance | 5.29e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 30.2      |\n",
      "|    reward             | 2.8698125 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 20.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 517         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -0.565      |\n",
      "|    reward             | -0.07050459 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | -25.9      |\n",
      "|    reward             | -1.3536363 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 14.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -68.1      |\n",
      "|    reward             | -0.8060558 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 82.2       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1533860.50\n",
      "total_reward: 533860.50\n",
      "total_cost: 2630.02\n",
      "total_trades: 853\n",
      "Sharpe: 1.181\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 77         |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | -0.6879828 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.57       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 78         |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.86      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -299       |\n",
      "|    reward             | 0.06483666 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.2e+03    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.88     |\n",
      "|    explained_variance | 0.000101  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -92       |\n",
      "|    reward             | 4.1803336 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 236       |\n",
      "-------------------------------------\n",
      "day: 188, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523391.01\n",
      "total_reward: 523391.01\n",
      "total_cost: 999.55\n",
      "total_trades: 864\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 518        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 5.82       |\n",
      "|    reward             | 0.33987954 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 34.3       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 518         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.87       |\n",
      "|    explained_variance | 0.00032     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -107        |\n",
      "|    reward             | -0.44100112 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 135         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -18.9     |\n",
      "|    reward             | 1.7472368 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.9      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 36.5      |\n",
      "|    reward             | -6.212647 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 89.2      |\n",
      "-------------------------------------\n",
      "day: 188, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523373.89\n",
      "total_reward: 523373.89\n",
      "total_cost: 999.44\n",
      "total_trades: 837\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 42.4      |\n",
      "|    reward             | 1.4080507 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 25.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    reward             | 3.886813 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 48.4     |\n",
      "|    reward             | 1.257358 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 46.3     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 518        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -24.7      |\n",
      "|    reward             | -0.5969062 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 7.78       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523439.92\n",
      "total_reward: 523439.92\n",
      "total_cost: 999.40\n",
      "total_trades: 852\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -21.1     |\n",
      "|    reward             | 0.8068054 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 6.68      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 517         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 20.5        |\n",
      "|    reward             | -0.28722128 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 16.4        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.91     |\n",
      "|    explained_variance | 1.19e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -178      |\n",
      "|    reward             | 4.0489235 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 695       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -32.6      |\n",
      "|    reward             | -1.7031703 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 24.8       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523440.10\n",
      "total_reward: 523440.10\n",
      "total_cost: 999.15\n",
      "total_trades: 847\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 133        |\n",
      "|    reward             | 0.13684379 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 175        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 62.4       |\n",
      "|    reward             | -4.1493278 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 40         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.95      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -56.7      |\n",
      "|    reward             | -0.9668387 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 52.6       |\n",
      "--------------------------------------\n",
      "day: 188, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1523220.55\n",
      "total_reward: 523220.55\n",
      "total_cost: 999.76\n",
      "total_trades: 931\n",
      "Sharpe: 1.168\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.95     |\n",
      "|    explained_variance | -0.000106 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 24.2      |\n",
      "|    reward             | 8.358591  |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -4.09    |\n",
      "|    reward             | 3.651703 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 6.42     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.93     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -84.7     |\n",
      "|    reward             | -8.955038 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 105       |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(\n",
    "    model=model_a2c,\n",
    "    tb_log_name='a2c',\n",
    "    total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c6b67a8-6069-4070-83ae-e9face22b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save(TRAINED_MODEL_DIR + '/agent_a2c') if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65451906-25c4-407b-9954-21ae5799826d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e83c508-fc5c-4b65-a9c5-f89c5d8cf22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 6, State Space: 61\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e85774cd-53c2-4e11-a927-407d19843180",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1_000_000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b75cdb44-0d59-4090-98bb-e738b4fc6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(\n",
    "    df = trade,\n",
    "    turbulence_threshold = 70,\n",
    "    risk_indicator_col = 'turbulence',\n",
    "    **env_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62a3f619-65c1-4968-a73b-9c2e80de450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c,\n",
    "    environment = e_trade_gym\n",
    ") if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc56f5a-b734-4dd4-a9e4-9a52ca178b97",
   "metadata": {},
   "source": [
    "# 3. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07bda558-f213-430d-b0f1-d7ac51f1eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "result = pd.DataFrame()\n",
    "if if_using_a2c:\n",
    "    result = pd.merge(result, df_result_a2c, how='outer', left_index = True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20cb93b3-8d2e-4e81-b65e-c127587b4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "col_name.append('A2C') if if_using_a2c else None\n",
    "result.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d233332b-4b9d-4985-9154-dbfaaf122127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9028bfa-5289-437f-a133-e602722f1242",
   "metadata": {},
   "source": [
    "# Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df348119-bdea-4798-a3ba-4dc1f4a4261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helps us process data into a form for weight calculation\n",
    "def process_df_for_mvo(df):\n",
    "    df = df.sort_values(['date', 'tic'], ignore_index=True)[['date', 'tic', 'close']]\n",
    "    fst = df\n",
    "    fst = fst.iloc[0:stock_dimension, :]\n",
    "    tic = fst['tic'].tolist()\n",
    "\n",
    "    mvo = pd.DataFrame()\n",
    "\n",
    "    for k in range(len(tic)):\n",
    "        mvo[tic[k]] = 0\n",
    "\n",
    "    for i in range(df.shape[0]//stock_dimension):\n",
    "        n = df\n",
    "        n = n.iloc[i*stock_dimension:(i+1)*stock_dimension, :]\n",
    "        date = n['date'][i*stock_dimension]\n",
    "        mvo.loc[date] = n['close'].tolist()\n",
    "\n",
    "    return mvo\n",
    "\n",
    "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
    "    import numpy as np\n",
    "    StockReturn = np.zeros([Rows-1, Columns])\n",
    "    for j in range(Columns):                     # j: Assets\n",
    "        for i in range(Rows-1):                  # i: Daily Prices\n",
    "            StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j]) * 100\n",
    "    return StockReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a179d184-eb6a-4b34-b76d-9650f3c641e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean returns of assets in k-portfolio 1\n",
      " [0.64  0.353 0.322 0.769 0.003 0.272]\n",
      "Variance-Covariance matrix of returns\n",
      " [[37.826 22.943 20.533 30.237 -1.621 23.699]\n",
      " [22.943 22.104 16.743 26.114 -1.267 19.52 ]\n",
      " [20.533 16.743 38.63  21.936 -1.093 20.577]\n",
      " [30.237 26.114 21.936 39.412 -1.64  28.297]\n",
      " [-1.621 -1.267 -1.093 -1.64   0.539 -1.179]\n",
      " [23.699 19.52  20.577 28.297 -1.179 26.437]]\n"
     ]
    }
   ],
   "source": [
    "StockData = process_df_for_mvo(train)\n",
    "TradeData = process_df_for_mvo(trade)\n",
    "\n",
    "TradeData.to_numpy()\n",
    "\n",
    "#compute asset returns\n",
    "arStockPrices = np.asarray(StockData)\n",
    "[Rows, Cols]=arStockPrices.shape\n",
    "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "# compute mean returns and variance covariance matrix of returns\n",
    "meanReturns = np.mean(arReturns, axis=0)\n",
    "covReturns = np.cov(arReturns, rowvar=False)\n",
    "\n",
    "# set precision for printing results\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# display mean returns and variance-covariance matrix of returns\n",
    "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "print('Variance-Covariance matrix of returns\\n', covReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4ebffbd-66c2-4667-b30b-65ce5d65fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "raw_weights_mean = ef_mean.max_sharpe()\n",
    "cleaned_weights_mean = ef_mean.clean_weights()\n",
    "mvo_weights = np.array([1_000_000 * cleaned_weights_mean[i] for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f243cd28-61e0-4ba3-ab47-eb8388d80334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>5.561047e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-04</th>\n",
       "      <td>5.656177e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05</th>\n",
       "      <td>5.866209e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-06</th>\n",
       "      <td>5.914494e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-07</th>\n",
       "      <td>5.933265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>6.673126e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>6.862875e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>6.824954e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>6.470923e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>6.209917e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Mean Var\n",
       "2021-10-01  5.561047e+06\n",
       "2021-10-04  5.656177e+06\n",
       "2021-10-05  5.866209e+06\n",
       "2021-10-06  5.914494e+06\n",
       "2021-10-07  5.933265e+06\n",
       "...                  ...\n",
       "2021-12-22  6.673126e+06\n",
       "2021-12-23  6.862875e+06\n",
       "2021-12-27  6.824954e+06\n",
       "2021-12-28  6.470923e+06\n",
       "2021-12-29  6.209917e+06\n",
       "\n",
       "[62 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "\n",
    "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "\n",
    "MVO_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "586ab9b4-5689-49a0-a9b3-e480cc0992a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "\n",
    "result = pd.DataFrame()\n",
    "if if_using_a2c:\n",
    "    result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63c16fe0-25bd-4307-819b-17b7568d6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "col_name.append('A2C') if if_using_a2c else None\n",
    "result.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "486f3663-42cd-4525-9849-ad1047c512e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2C</th>\n",
       "      <th>Mean Var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>5.561047e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-04</th>\n",
       "      <td>1.019275e+06</td>\n",
       "      <td>5.656177e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05</th>\n",
       "      <td>1.068781e+06</td>\n",
       "      <td>5.866209e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-06</th>\n",
       "      <td>1.145085e+06</td>\n",
       "      <td>5.914494e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-07</th>\n",
       "      <td>1.114261e+06</td>\n",
       "      <td>5.933265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>1.018842e+06</td>\n",
       "      <td>6.673126e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>1.063268e+06</td>\n",
       "      <td>6.862875e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>1.061570e+06</td>\n",
       "      <td>6.824954e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>9.981391e+05</td>\n",
       "      <td>6.470923e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>9.734485e+05</td>\n",
       "      <td>6.209917e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A2C      Mean Var\n",
       "date                                  \n",
       "2021-10-01  1.000000e+06  5.561047e+06\n",
       "2021-10-04  1.019275e+06  5.656177e+06\n",
       "2021-10-05  1.068781e+06  5.866209e+06\n",
       "2021-10-06  1.145085e+06  5.914494e+06\n",
       "2021-10-07  1.114261e+06  5.933265e+06\n",
       "...                  ...           ...\n",
       "2021-12-22  1.018842e+06  6.673126e+06\n",
       "2021-12-23  1.063268e+06  6.862875e+06\n",
       "2021-12-27  1.061570e+06  6.824954e+06\n",
       "2021-12-28  9.981391e+05  6.470923e+06\n",
       "2021-12-29  9.734485e+05  6.209917e+06\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(result, MVO_result, how='outer', left_index=True, right_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92f45175-b580-4d30-ba60-f063f79d640a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f022a-35dc-4fcb-bc38-79e3dd883848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
